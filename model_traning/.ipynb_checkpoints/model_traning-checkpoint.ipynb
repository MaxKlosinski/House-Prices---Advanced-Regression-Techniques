{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3913e48c-9636-4f6d-9bec-e5d7c567884a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### A great library, but unfortunately only compatible with Linux.\n",
    "# import ydf\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import optunahub\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # To divide data into training and validation sets\n",
    "from sklearn.metrics import mean_squared_error # To evaluate the model\n",
    "from sklearn.model_selection import KFold # For dividing data into training and validation sets using the Kfold method\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6fb4a6-b478-402c-880e-ada5a1fb25f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea', 'count_of_porch', 'sum_of_area_porch']\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "GarageCars\n",
      "GarageArea\n",
      "count_of_porch\n",
      "sum_of_area_porch\n",
      "(1445, 65)\n",
      "(1459, 64)\n"
     ]
    }
   ],
   "source": [
    "train_ds_full = pd.read_csv(\"../future_engenerring/recorded_analyzed_data/Normalne_dane_treningowe.csv\")\n",
    "\n",
    "test_ds = pd.read_csv(\"../future_engenerring/recorded_analyzed_data/Test_ZimputowaneDane_MetodaLGB_zakodowaneWartościTekstowe.csv\")\n",
    "\n",
    "# Manually filter columns by type because for some reason the search function is not working properly.\n",
    "object_cols = []\n",
    "\n",
    "for col in train_ds_full:\n",
    "    if train_ds_full[col].dtype.name != 'float64' and train_ds_full[col].dtype.name != 'int64':\n",
    "        object_cols.append(col)\n",
    "\n",
    "# We need to convert columns containing categorical values.\n",
    "# This is a necessary step in order to automate the encoding of these values, which are used in the XGBoost function.\n",
    "for col in object_cols:\n",
    "    test_ds[col] = test_ds[col].astype('category')\n",
    "    train_ds_full[col] = train_ds_full[col].astype('category')\n",
    "\n",
    "train_ds_full = train_ds_full.drop(columns=['Unnamed: 0'])\n",
    "test_ds = test_ds.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# The MSSubClass column contains numeric values but is described in the document as a categorical attribute, so we need to change its data type.\n",
    "train_ds_full['MSSubClass'] = train_ds_full['MSSubClass'].astype('category')\n",
    "test_ds['MSSubClass'] = test_ds['MSSubClass'].astype('category')\n",
    "\n",
    "object_cols.clear()\n",
    "\n",
    "for col in test_ds:\n",
    "    if test_ds[col].dtype.name == 'object':\n",
    "        object_cols.append(col)\n",
    "\n",
    "print(object_cols)\n",
    "\n",
    "for col in object_cols:\n",
    "    print(col)\n",
    "    test_ds[col] = pd.to_numeric(test_ds[col], errors='coerce').astype('float64')\n",
    "\n",
    "print(train_ds_full.shape)\n",
    "print(test_ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb9bbb-9433-46a2-8bd5-a243ed4e0ed4",
   "metadata": {},
   "source": [
    "# Using K-Fold instead of StratifiedKFold\n",
    "I used the standard k-fold splitting method instead of stratified k-fold for two reasons:\n",
    "1. StratifiedKFold can only be used on classification data, not regression data.\n",
    "2. Direct use of StratifiedKFold was not possible because the model solves a regression problem (predicting a continuous price) rather than a classification problem. Artificially dividing prices into intervals (binning) to enforce stratification would introduce unnecessary complexity, so standard KFold with random shuffling was chosen.\n",
    "\n",
    "# Data breakdown for optiuna\n",
    "The data must be divided so that Optiuna can compare its analyses.\n",
    "\n",
    "# K-Fold data brakedown\n",
    "I used a single division using the K-Fold Cross-Validation method (5 divisions). This ensures that each record in the dataset is used exactly once as a test set and four times as a training set. This eliminates the problem of ‘unlucky sampling’, where difficult cases would be omitted from the learning or validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10663866-3a4d-4377-8f9e-f4cdfb7d2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold splitting\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300c9b1-4ab1-4fc8-84c5-e9bab125de47",
   "metadata": {},
   "source": [
    "# Things you need to do for Optiuna to work\n",
    "1. You need to define the “objective” function with the “trial” argument.\n",
    "2. Create a dictionary of hyperparameters and use the “trial” function to set the ranges of numbers that will be inserted into these hyperparameters.\n",
    "3. This function must return a metric according to which the hyperparameters will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a6893d-a2ad-4fa0-b8f5-e9fe650ac4e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggesting hyperparameter values for Optuna to test\n",
    "    params_to_learn = {\n",
    "        # \"max_depth\": trial.suggest_int(\"max_depth\", 4, 13),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 900),\n",
    "        \"max_leaves\" : trial.suggest_int(\"max_leaves\", 15, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.1, 0.5, log=True),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1, 5.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 5.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        enable_categorical = True,\n",
    "        **params_to_learn\n",
    "    )\n",
    "\n",
    "    table_of_mean_kfold_predictions = []\n",
    "    \n",
    "    for i, (train_index, validation_index) in enumerate(kf.split(train_ds_full)):\n",
    "\n",
    "        train_ds_subset = train_ds_full.iloc[train_index]\n",
    "        # This value is required by the XGBoost regression function to identify the target variable.\n",
    "        train_ds_subset_saleprice = train_ds_subset[\"SalePrice\"]\n",
    "\n",
    "        validation_ds_subset = train_ds_full.iloc[validation_index]\n",
    "        validation_ds_subset_saleprice = validation_ds_subset[\"SalePrice\"]\n",
    "\n",
    "        # Training the model.\n",
    "        model.fit(train_ds_subset, train_ds_subset_saleprice)\n",
    "\n",
    "        # Predicts values on the validation set\n",
    "        predictions = model.predict(validation_ds_subset)\n",
    "        \n",
    "        # Calculates the error (RMSE - Root Mean Squared Error) that we want to minimize.\n",
    "        rmse = np.sqrt(mean_squared_error(validation_ds_subset_saleprice, predictions))\n",
    "        \n",
    "        table_of_mean_kfold_predictions.append(rmse)\n",
    "        print(np.mean(table_of_mean_kfold_predictions))\n",
    "\n",
    "    return np.mean(table_of_mean_kfold_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020f2c7e-285a-4882-85a1-20a9d4a97344",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 14:27:02,258] A new study created in RDB with name: home-price-prediction\n",
      "  0%|                                                                                                                                            | 0/30 [00:39<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2026-01-12 14:27:41,825] Trial 0 failed with parameters: {'n_estimators': 538, 'max_leaves': 77, 'max_bin': 186, 'learning_rate': 0.12727204765027955, 'booster': 'dart', 'reg_alpha': 1.4654238245894475, 'reg_lambda': 1.8572699677181645, 'gamma': 2.586658197952358, 'min_child_weight': 9} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_23733/2990506710.py\", line 33, in objective\n",
      "    model.fit(train_ds_subset, train_ds_subset_saleprice)\n",
      "    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/sklearn.py\", line 1370, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        callbacks=self.callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/demo/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-12 14:27:41,829] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We want to minimize the error, so direction='minimize'.\u001b[39;00m\n\u001b[32m      2\u001b[39m study = optuna.create_study(storage=\u001b[33m\"\u001b[39m\u001b[33msqlite:///db.sqlite3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m                             study_name=\u001b[33m\"\u001b[39m\u001b[33mhome-price-prediction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m                             direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimization completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     30\u001b[39m validation_ds_subset_saleprice = validation_ds_subset[\u001b[33m\"\u001b[39m\u001b[33mSalePrice\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Training the model.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds_subset_saleprice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Predicts values on the validation set\u001b[39;00m\n\u001b[32m     36\u001b[39m predictions = model.predict(validation_ds_subset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/sklearn.py:1370\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1368\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.13/site-packages/xgboost/core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# We want to minimize the error, so direction='minimize'.\n",
    "study = optuna.create_study(storage=\"sqlite:///db.sqlite3\",\n",
    "                            study_name=\"home-price-prediction2\",\n",
    "                            direction='minimize')\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Optimization completed.\")\n",
    "print(f\"Najlepsza próba: {study.best_trial.number}\")\n",
    "print(f\"Najlepszy wynik (RMSE): {study.best_value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Train the final model with the best parameters found on the FULL training set.\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Training the final model with the best parameters...\")\n",
    "final_model = xgb.XGBRegressor(\n",
    "    enable_categorical = True,\n",
    "    **study.best_params\n",
    ")\n",
    "\n",
    "final_model = final_model.fit(train_ds_full.drop(columns=['SalePrice']), train_ds_full['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3819e5-0f4a-42bf-883c-c077b80a975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "xgb.plot_importance(final_model, max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ee42a-6ab3-4241-87a8-c33cdec10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on the test set and save the results.\n",
    "print(\"Generating forecasts on the test set...\")\n",
    "prognozy = final_model.predict(test_ds)\n",
    "print(prognozy)\n",
    "prognozy = np.expm1(prognozy)\n",
    "\n",
    "lista = []\n",
    "for i in prognozy:\n",
    "    lista.append(i)\n",
    "\n",
    "lista_ids = []\n",
    "for i in range(1461,2920):\n",
    "    lista_ids.append(i)\n",
    "\n",
    "df = pd.DataFrame({'Id': lista_ids, 'SalePrice': lista})\n",
    "df.to_csv('../data_returned_by_model/out_optuna.csv', index=False)\n",
    "\n",
    "print(\"The results were saved to the file out_optuna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08339fd-d0ce-4876-85be-c736dacf0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal command for Optiuna to read the completed hyperparameter analysis. You must specify the main path to the file.\n",
    "# optuna-dashboard sqlite:///\"C:\\Users\\Joint\\Documents\\Moje projekty\\Przewidywanie cen domów\\db.sqlite3\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
