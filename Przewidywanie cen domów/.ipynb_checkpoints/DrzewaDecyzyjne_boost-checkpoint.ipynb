{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3913e48c-9636-4f6d-9bec-e5d7c567884a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joint\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Świetna biblioteka, ale niestety kompatybilna tylko z systemem linux\n",
    "#import ydf\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import optunahub\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # Do podziału danych na zbiór treningowy i walidacyjny\n",
    "from sklearn.metrics import mean_squared_error # Do oceny modelu\n",
    "from sklearn.model_selection import KFold # Do podziału danych na zbiór treningowy i walidacyjny metodą Kfold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af7383-9510-473a-8065-e611a9f5b3f4",
   "metadata": {},
   "source": [
    "Wczytywanie danych na których będę dokonwwał trenowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedf5374-9a9a-4bd2-8156-6aca57880789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_full = pd.read_csv(\"./Future Engenering/Przetworzone dane/Normalne_dane_treningowe.csv\")\n",
    "\n",
    "test_ds = pd.read_csv(\"./Future Engenering/Przetworzone dane/Test_ZimputowaneDane_MetodaLGB_zakodowaneWartościTekstowe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b36465-5676-4c67-ac1f-f3114bd74a5d",
   "metadata": {},
   "source": [
    "Przygotowanie typów danych dla karzdej kolumny ponieważ ja kożystam w moim modelu z automatycznego kodowania danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6fb4a6-b478-402c-880e-ada5a1fb25f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "GarageCars\n",
      "GarageArea\n",
      "count_of_porch\n",
      "sum_of_area_porch\n",
      "(1445, 65)\n",
      "(1459, 64)\n"
     ]
    }
   ],
   "source": [
    "# Ręczne filtrowanie kolumn typów ponieważ funkcja która powinna automatycznie wykonywać te wykrywanie typów nie działa prawidłowo.\n",
    "object_cols = []\n",
    "\n",
    "for col in train_ds_full:\n",
    "    if train_ds_full[col].dtype.name != 'float64' and train_ds_full[col].dtype.name != 'int64':\n",
    "        object_cols.append(col)\n",
    "\n",
    "# Musimy przekonwertować kolumny zawierające wartości kategoryczne. \n",
    "# Jest to niezbędny krok w celu zautomatyzowania kodowania tych wartości, które są wykorzystywane w funkcji XGBoost.\n",
    "for col in object_cols:\n",
    "    test_ds[col] = test_ds[col].astype('category')\n",
    "    train_ds_full[col] = train_ds_full[col].astype('category')\n",
    "\n",
    "train_ds_full = train_ds_full.drop(columns=['Unnamed: 0'])\n",
    "test_ds = test_ds.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Chociaż kolumna zawiera wartości liczbowe, jest opisana jako cecha kategoryczna, więc musimy zmienić jej typ danych.\n",
    "train_ds_full['MSSubClass'] = train_ds_full['MSSubClass'].astype('category')\n",
    "test_ds['MSSubClass'] = test_ds['MSSubClass'].astype('category')\n",
    "\n",
    "object_cols.clear()\n",
    "\n",
    "for col in test_ds:\n",
    "    if test_ds[col].dtype.name == 'object':\n",
    "        object_cols.append(col)\n",
    "\n",
    "for col in object_cols:\n",
    "    print(col)\n",
    "    test_ds[col] = pd.to_numeric(test_ds[col], errors='coerce').astype('float64')\n",
    "\n",
    "print(train_ds_full.shape)\n",
    "print(test_ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb9bbb-9433-46a2-8bd5-a243ed4e0ed4",
   "metadata": {},
   "source": [
    "# Podział danych\n",
    "Podział danych musi nastąpić by optiuna miała dzięki czemu porównywać swoje dokonane analizy.\n",
    "Dodatkowo podział danych musi nastąpić poprzez stratyfikacje bo danych jest za mało i to doprowadzało by do błędnych wniosków.\n",
    "\n",
    "# K-Fold podział danych\n",
    "Dodatkowo umieszcze podział danych w pętli trenowania modelu ponieważ będę trenował z pomocą k-foldowej metody dzielenia danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10663866-3a4d-4377-8f9e-f4cdfb7d2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzielenie na K-fold\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300c9b1-4ab1-4fc8-84c5-e9bab125de47",
   "metadata": {},
   "source": [
    "# Rzeczy jakie trzeba wykonać by optiuna działąła\n",
    "1. Trzeba zdefiniować funkcję \"objective\" z argumetem \"trial\"\n",
    "2. Tworzymy słownik hiperparametrów i w nim za pomocą funkcji \"trial\" ustalamy przedziały liczb które będą wstawiane w tych hiperparametrach.\n",
    "3. ta funcja musi zwracać metrykę według której będą zmieniane hiperparametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a6893d-a2ad-4fa0-b8f5-e9fe650ac4e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Sugeruj wartości hiperparametrów, które Optuna ma przetestować\n",
    "    params_to_learn = {\n",
    "        # \"max_depth\": trial.suggest_int(\"max_depth\", 4, 13),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 900),\n",
    "        \"max_leaves\" : trial.suggest_int(\"max_leaves\", 15, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.1, 0.5, log=True),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1, 5.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 5.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        enable_categorical = True,\n",
    "        **params_to_learn\n",
    "    )\n",
    "\n",
    "    table_of_mean_kfold_predictions = []\n",
    "    \n",
    "    for i, (train_index, validation_index) in enumerate(kf.split(train_ds_full)):\n",
    "\n",
    "        train_ds_subset = train_ds_full.iloc[train_index]\n",
    "        # Wartość ta jest wymagana przez funkcję regresji XGBoost w celu identyfikacji zmiennej docelowej.\n",
    "        train_ds_subset_saleprice = train_ds_subset[\"SalePrice\"]\n",
    "\n",
    "        validation_ds_subset = train_ds_full.iloc[validation_index]\n",
    "        validation_ds_subset_saleprice = validation_ds_subset[\"SalePrice\"]\n",
    "\n",
    "        # Trenowanie modelu.\n",
    "        model.fit(train_ds_subset, train_ds_subset_saleprice)\n",
    "\n",
    "        # Przewiduje wartości na zbiorze walidacyjnym\n",
    "        predictions = model.predict(validation_ds_subset)\n",
    "        \n",
    "        # Oblicza błąd (RMSE - Root Mean Squared Error), który chcemy minimalizować\n",
    "        rmse = np.sqrt(mean_squared_error(validation_ds_subset_saleprice, predictions))\n",
    "        \n",
    "        table_of_mean_kfold_predictions.append(rmse)\n",
    "        print(np.mean(table_of_mean_kfold_predictions))\n",
    "\n",
    "    return np.mean(table_of_mean_kfold_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020f2c7e-285a-4882-85a1-20a9d4a97344",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "DuplicatedStudyError",
     "evalue": "Another study with name 'przewidywanie-cen-domow21' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:951\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIntegrityError\u001b[39m: UNIQUE constraint failed: studies.study_name",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:275\u001b[39m, in \u001b[36mRDBStorage.create_new_study\u001b[39m\u001b[34m(self, directions, study_name)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_create_scoped_session\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscoped_session\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\contextlib.py:148\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:80\u001b[39m, in \u001b[36m_create_scoped_session\u001b[39m\u001b[34m(scoped_session, ignore_integrity_error)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m session\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc.IntegrityError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2030\u001b[39m, in \u001b[36mSession.commit\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2028\u001b[39m     trans = \u001b[38;5;28mself\u001b[39m._autobegin_t()\n\u001b[32m-> \u001b[39m\u001b[32m2030\u001b[39m \u001b[43mtrans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_root\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36mcommit\u001b[39m\u001b[34m(self, _to_root)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:137\u001b[39m, in \u001b[36m_StateChange.declare_states.<locals>._go\u001b[39m\u001b[34m(fn, self, *arg, **kw)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     ret_value = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1311\u001b[39m, in \u001b[36mSessionTransaction.commit\u001b[39m\u001b[34m(self, _to_root)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expect_state(SessionTransactionState.PREPARED):\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nested:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36m_prepare_impl\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:137\u001b[39m, in \u001b[36m_StateChange.declare_states.<locals>._go\u001b[39m\u001b[34m(fn, self, *arg, **kw)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     ret_value = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1286\u001b[39m, in \u001b[36mSessionTransaction._prepare_impl\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4331\u001b[39m, in \u001b[36mSession.flush\u001b[39m\u001b[34m(self, objects)\u001b[39m\n\u001b[32m   4330\u001b[39m     \u001b[38;5;28mself\u001b[39m._flushing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4331\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4332\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4466\u001b[39m, in \u001b[36mSession._flush\u001b[39m\u001b[34m(self, objects)\u001b[39m\n\u001b[32m   4465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4466\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_capture_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4427\u001b[39m, in \u001b[36mSession._flush\u001b[39m\u001b[34m(self, objects)\u001b[39m\n\u001b[32m   4426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4427\u001b[39m     \u001b[43mflush_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4428\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:466\u001b[39m, in \u001b[36mUOWTransaction.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m topological.sort(\u001b[38;5;28mself\u001b[39m.dependencies, postsort_actions):\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[43mrec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:642\u001b[39m, in \u001b[36mSaveUpdateAll.execute\u001b[39m\u001b[34m(self, uow)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;129m@util\u001b[39m.preload_module(\u001b[33m\"\u001b[39m\u001b[33msqlalchemy.orm.persistence\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, uow):\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreloaded\u001b[49m\u001b[43m.\u001b[49m\u001b[43morm_persistence\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstates_for_mapper_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:93\u001b[39m, in \u001b[36msave_obj\u001b[39m\u001b[34m(base_mapper, states, uowtransaction, single)\u001b[39m\n\u001b[32m     85\u001b[39m     _emit_update_statements(\n\u001b[32m     86\u001b[39m         base_mapper,\n\u001b[32m     87\u001b[39m         uowtransaction,\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m         update,\n\u001b[32m     91\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43m_emit_insert_statements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_mapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43muowtransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m _finalize_insert_update_commands(\n\u001b[32m    102\u001b[39m     base_mapper,\n\u001b[32m    103\u001b[39m     uowtransaction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m     ),\n\u001b[32m    120\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:1233\u001b[39m, in \u001b[36m_emit_insert_statements\u001b[39m\u001b[34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping, use_orm_insert_stmt, execution_options)\u001b[39m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m primary_key = result.inserted_primary_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1419\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:526\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1641\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1633\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1634\u001b[39m     dialect=dialect,\n\u001b[32m   1635\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1639\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1640\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2356\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:951\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIntegrityError\u001b[39m: (sqlite3.IntegrityError) UNIQUE constraint failed: studies.study_name\n[SQL: INSERT INTO studies (study_name) VALUES (?)]\n[parameters: ('przewidywanie-cen-domow21',)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDuplicatedStudyError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Chcemy zminimalizować błąd, więc direction='minimize'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m study = \u001b[43moptuna\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msqlite:///db.sqlite3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprzewidywanie-cen-domow21\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mminimize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m study.optimize(objective, n_trials=\u001b[32m1\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\_convert_positional_args.py:135\u001b[39m, in \u001b[36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n\u001b[32m    133\u001b[39m kwargs.update(inferred_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\study\\study.py:1297\u001b[39m, in \u001b[36mcreate_study\u001b[39m\u001b[34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[39m\n\u001b[32m   1295\u001b[39m storage = storages.get_storage(storage)\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     study_id = \u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.DuplicatedStudyError:\n\u001b[32m   1299\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m load_if_exists:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:78\u001b[39m, in \u001b[36m_CachedStorage.create_new_study\u001b[39m\u001b[34m(self, directions, study_name)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_new_study\u001b[39m(\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m, directions: Sequence[StudyDirection], study_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     77\u001b[39m ) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     study_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m     80\u001b[39m         study = _StudyInfo()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\DataMax\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:287\u001b[39m, in \u001b[36mRDBStorage.create_new_study\u001b[39m\u001b[34m(self, directions, study_name)\u001b[39m\n\u001b[32m    284\u001b[39m         session.add(models.StudyModel(study_name=study_name, directions=direction_models))\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc.IntegrityError:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m optuna.exceptions.DuplicatedStudyError(\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAnother study with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m already exists. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease specify a different name, or reuse the existing one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mby setting `load_if_exists` (for Python API) or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`--skip-if-exists` flag (for CLI).\u001b[39m\u001b[33m\"\u001b[39m.format(study_name)\n\u001b[32m    292\u001b[39m     )\n\u001b[32m    294\u001b[39m _logger.info(\u001b[33m\"\u001b[39m\u001b[33mA new study created in RDB with name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(study_name))\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_study_id_from_name(study_name)\n",
      "\u001b[31mDuplicatedStudyError\u001b[39m: Another study with name 'przewidywanie-cen-domow21' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI)."
     ]
    }
   ],
   "source": [
    "# Chcemy zminimalizować błąd, więc direction='minimize'\n",
    "study = optuna.create_study(storage=\"sqlite:///db.sqlite3\",\n",
    "                            study_name=\"przewidywanie-cen-domow21\",\n",
    "                            direction='minimize')\n",
    "study.optimize(objective, n_trials=1, show_progress_bar=True)\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Zakończono optymalizację.\")\n",
    "print(f\"Najlepsza próba: {study.best_trial.number}\")\n",
    "print(f\"Najlepszy wynik (RMSE): {study.best_value}\")\n",
    "print(\"Najlepsze hiperparametry:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 5. Wytrenuj ostateczny model z najlepszymi znalezionymi parametrami na PEŁNYM zbiorze treningowym\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Trenowanie ostatecznego modelu z najlepszymi parametrami...\")\n",
    "final_model = xgb.XGBRegressor(\n",
    "    enable_categorical = True,\n",
    "    **study.best_params\n",
    ")\n",
    "\n",
    "final_model = final_model.fit(train_ds_full.drop(columns=['SalePrice']), train_ds_full['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3819e5-0f4a-42bf-883c-c077b80a975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "xgb.plot_importance(final_model, max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ee42a-6ab3-4241-87a8-c33cdec10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Wykonaj predykcje na zbiorze testowym i zapisz wyniki\n",
    "print(\"Generowanie prognoz na zbiorze testowym...\")\n",
    "prognozy = final_model.predict(test_ds)\n",
    "print(prognozy)\n",
    "prognozy = np.expm1(prognozy)\n",
    "\n",
    "lista = []\n",
    "for i in prognozy:\n",
    "    lista.append(i)\n",
    "\n",
    "lista_ids = []\n",
    "for i in range(1461,2920):\n",
    "    lista_ids.append(i)\n",
    "\n",
    "df = pd.DataFrame({'Id': lista_ids, 'SalePrice': lista})\n",
    "df.to_csv('./Zapisany model i analiza/out_optuna.csv', index=False)\n",
    "\n",
    "print(\"Wyniki zapisano do pliku out_optuna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08339fd-d0ce-4876-85be-c736dacf0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polecenie do terminala dla optiuny, Trzevba podać główną ścieżkę do pliku\n",
    "# optuna-dashboard sqlite:///\"C:\\Users\\Joint\\Documents\\Moje projekty\\Przewidywanie cen domów\\db.sqlite3\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
